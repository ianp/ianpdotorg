<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Programming | Digital Magpie]]></title>
  <link href="http://ianp.org/categories/programming/atom.xml" rel="self"/>
  <link href="http://ianp.org/"/>
  <updated>2013-01-15T14:48:48+01:00</updated>
  <id>http://ianp.org/</id>
  <author>
    <name><![CDATA[Ian Phillips]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Programming Praxis]]></title>
    <link href="http://ianp.org/2013/01/15/programming-praxis"/>
    <updated>2013-01-15T14:03:00+01:00</updated>
    <id>http://ianp.org/2013/01/15/programming-praxis</id>
    <content type="html"><![CDATA[<p>Over the weekend I stumbled across the <a href="http://programmingpraxis.com">Programming Praxis</a> web site, a blog that aims to “publishes new programming exercises weekly, at least, so that savvy programmers can maintain their skills by working the exercises and thinking outside their normal skill set”. It’s been running for about three years now and at the time of writing there are almost 400 problems there. I thought that I’d like to have a go at solving a few of them, I’m going to try solving them in Java initially, and then maybe revisit them in other languages to compare the solutions.</p>

<p>I’ve got solutions to the first couple of problems ready to go, and all of my solutions can be found in <a href="http://github.com/ianp/praxis-java">this project</a> on GitHub.</p>

<h3 id="reverse-polish-notation-calculator">Reverse Polish Notation Calculator</h3>

<p>This is trivial to implement in Java using the built in <code>Console</code> class, the complete implementation (sans class boilerplace and imports) is:</p>

<p>```java
private static final Console console = System.console();
private static final Deque<bigdecimal> stack = new ArrayDeque&lt;&gt;();</bigdecimal></p>

<p>private static void processLine(String line) {
    for (String s : line.split(“\s+”)) {
        if (“+”.equals(s)) {
            stack.push(stack.pop().add(stack.pop()));
        } else if (“-“.equals(s)) {
            stack.push(stack.pop().subtract(stack.pop()));
        } else if (“*“.equals(s)) {
            stack.push(stack.pop().multiply(stack.pop()));
        } else if (“/”.equals(s)) {
            stack.push(stack.pop().divide(stack.pop()));
        } else if (“exit”.equalsIgnoreCase(s) || “quit”.equalsIgnoreCase(s)) {
            System.exit(0);
        } else {
            stack.push(new BigDecimal(s));
        }
    }
    console.format(“%s%n”, stack.peek()).flush();
}</p>

<p>public static void main(String[] args) {
    try {
        String line;
        while ((line = console.readLine(“&gt; “)) != null) {
            processLine(line);
        }
    } catch (Exception e) {
        console.format(“%s: %s%n”, e.getClass().getSimpleName(), e.getMessage());
    }
}
```</p>

<p>Compared with other solutions the only interesting things are the use of <code>BigDecimal</code> instead of primitive types, this means that the calculator supports a wider range of numbers and input formats, and the use of a <code>Deque</code> as the stack, this is a more modern class than the old Java 1.0 vintage <code>Stack</code> class.</p>

<p>The full class is <a href="https://github.com/ianp/praxis-java/blob/master/src/main/java/org/ianp/praxis/RPNCalculator.java">here</a>.</p>

<h3 id="sieve-of-eratosthenes">Sieve of Eratosthenes</h3>

<p>This classic algotrithm is a bit more interesting: my first thought was to lazily create the list of primes using modulo checks to filter out non-prime numbers. Technically this isn’t the Sieve of Eratosthenes, but it’s logically the same. Well, it performed terribly taking several seconds to compute the first million primes.</p>

<p>It turns out that one of the reasons the actual sieve is so fast is that it only uses addition rather than the more expensive modulo operations. This, plus the memory saving gained from using a <code>BitSet</code> instead of a list of <code>Integer</code>s gave me a nice, zippy, implementation. The relevant method is:</p>

<p><code>java
public static BitSet sieve(int target) {
    BitSet primes = new BitSet(target);
    if (target &lt; 2) { return primes; }
    primes.set(2);
    if (target &lt; 3) { return primes; }
    for (int i = 3; i &lt;= target; i += 2) {
        primes.set(i);
    }
    for (int prime = 3; prime * prime &lt; target; prime = primes.nextSetBit(prime + 1)) {
        for (int i = prime + prime; i &lt;= target; i += prime) {
            primes.clear(i);
        }
    }
    return primes;
}
</code></p>

<p>And of course in a real implementation this would be a good candidate for memoization giving you <em>O(1)</em> performance in the common case.</p>

<p>The full class is <a href="https://github.com/ianp/praxis-java/blob/master/src/main/java/org/ianp/praxis/SieveOfEratosthenes.java">here</a>.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Builders and Factories]]></title>
    <link href="http://ianp.org/2013/01/09/builders-and-factories"/>
    <updated>2013-01-09T18:41:00+01:00</updated>
    <id>http://ianp.org/2013/01/09/builders-and-factories</id>
    <content type="html"><![CDATA[<p>I started to write a ‘quick’ response to <a href="http://toomuchcoding.blogspot.ie/2013/01/hamcrest-matchers-guava-predicate-and.html">this post about builders</a> and it kind of got out of hand, so I’m putting it up here instead.</p>

<p>The post isn’t bad, but I think that Marcin is getting the builder and factory patterns a little mixed up. To recap:</p>

<p>The intent of the <strong>Builder Pattern</strong> is to separate out the construction of an object from it’s final representation. Doing this makes it easier to enforce preconditions and invariants, and also makes the object construction easier to read in languages without keyword arguments.</p>

<p>The intent of the <strong>Factory Pattern</strong> on the other hand, is to delegate responsibility for creating an object to somebody else. It is commonly used in dependency injection frameworks.</p>

<p>A concrete example should serve to illustrate the differences.</p>

<h3 id="a-builder-example">A Builder Example</h3>

<p>Assume that we have an interface for a simple Pojo:</p>

<p><code>java
public interface Employee {
    public Date getHiredAt();
    public String getId();
    public String getName();
    public int getSalary();
    public String getTitle();
}
</code></p>

<p>and a default implementation (shown here as a separae class, but it could also be a static inner class in the interface):</p>

<p>```java
class EmployeeImpl implements Employee {</p>

<pre><code>private final String _id;
private final String _name;
private final String _title;
private final int _salary;
private final Date _hiredAt;

EmployeeImpl(String id, String name, String title, int salary, Date hiredAt) {
    _id = id;
    _name = name;
    _title = title;
    _salary = salary;
    _hiredAt = hiredAt;
}

public Date getHiredAt() {
    return _hiredAt;
}

public String getId() {
    return _id;
}

// ...

@Override
public String toString() {
    return Objects.toStringHelper(this).omitNullValues()
        .add("id", _id)
        .add("name", _name)
        .add("title", _title)
        .add("salary", _salary)
        .add("hiredAt", _hiredAt)
        .toString();
} } ```
</code></pre>

<p>Even with just a few fields like this invoking the constructor becomes somewhat ugly:</p>

<p><code>java
Employee e = new EmployeeImpl(
    "1", "Fred Foobar", "Engineer", 100000, new Date());
</code></p>

<p>Without referring to the docs or source code how do you know what all of those strings mean? How do you know that you have them in the correct order? And if it seems reasonable clear in this example imaging if your Pojo was mainly non-string data!</p>

<p><code>java
MyPojo p = new MyPojoImpl(123, true false, false 45.83, "wtf???");
</code></p>

<p>Clear as mud, right?</p>

<p>Other languages don’t have this problem, for example in Objective-C we would write something like:</p>

<p><code>objc
id obj = [EGEmployee employeeWithId:@"1" name:@"Fred Foobar"
        title:@"Apple Engineer" salary:200000 hiredAt:@"2001-03-24"];
</code></p>

<p>which is much clearer. Ruby, Python, and other languages all have similar constructs. Adding a builder allows us to gain the same level of clarity in Java, and it provides a good place for us to perform any additional checks before creating the object. Here’s a typical implementation and an example of calling it:</p>

<p>```java
public class Builder {</p>

<pre><code>private static final AtomicInteger _ids = new AtomicInteger();

private static String checkString(String value, String name) {
    value = nullToEmpty(value).trim();
    checkArgument(!value.isEmpty(), "%s cannot be null or empty", name);
    return value;
}

private String _id;
private String _name;
private String _title;
private Integer _salary;
private Date _hiredAt;

public Builder hiredAt(Date hiredAt) {
    _hiredAt = hiredAt;
    return this;
}

public Builder id(String id) {
    _id = id;
    return this;
}

public Builder name(String name) {
    _name = name;
    return this;
}

public Builder salary(int salary) {
    checkArgument(salary &gt;= 0, "salary cannot be negative");
    _salary = salary;
    return this;
}

public Builder title(String title) {
    _title = title;
    return this;
}

public Employee build() {
    return new Impl(
            _id != null ? _id : String.format("emp:%06d", _ids.incrementAndGet()),
            checkString(_name, "name"),
            checkString(_title, "title"),
            checkNotNull(_salary, "salary"),
            _hiredAt != null ? _hiredAt : new Date());
} }
</code></pre>

<p>// elsewhere …
public Employee findEmployeeById(String id) {
    if (“1”.equals(id)) {
        return new Builder().id(id)
            .name(“Fred Foobar”)
            .title(“Engineer”)
            .salary(100000)
            .hiredAt(“2001-03-24”).build();
    }
    return null;
}
```</p>

<p>Again, all pretty clear now, and HotSpot will inline all of those method calls no there should be no additional overhead once the JVM is up and running. </p>

<h3 id="a-factory-example">A Factory Example</h3>

<p>Factories are different, but it would be common for a factory to <em>use</em> a builder to create the objects that it vends. For example, here is a factory for employee objects (it doesn’t need to have the word Factory in it’s name):</p>

<p><code>java
public interface Employees {
    Iterable&lt;Employee&gt; all();
    Employee findbyId(String id);
}
</code></p>

<p>We can then have different implementations of this, maybe one that loads data from a CSV or JSON file for testing purposes, and one that loads data via JDBC for production use.</p>

<p><strong>Aside:</strong> if you’re familiar with <em>domain-driven design</em> you’ll be forgiven for noticing a lot of overlap between the factory pattern and DDD’s concept of <em>repositories,</em> they’re very similar concepts. One difference being that factories are often able to create new objects <em>ex nihilo</em> while repositories usually retreive objects from external sources. Compare the <code>findById()</code> method with the <code>newInstance()</code> methods employed by many of the factory classes in the JDK.</p>

<p>Hopefully you can see from this post that the two patterns have different—if complementary—aims.</p>

<p>A complete example project with all of this code, as well as test cases and a CSV based implementation the the factory are available <a href="https://github.com/ianp/builder-example">on Github</a>.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[VLC Versions]]></title>
    <link href="http://ianp.org/2012/10/30/vlc-versions"/>
    <updated>2012-10-30T18:49:00+01:00</updated>
    <id>http://ianp.org/2012/10/30/vlc-versions</id>
    <content type="html"><![CDATA[<p>So I started up <a href="http://www.videolan.org" title="VLC media player">VLC</a> just now and was greeted with this update notification:</p>

<blockquote>
  <p>VLC media player 2.0.4</p>

  <p>This is a <strong>major update</strong> that fixes a lot of regressions of the 2.0.x branch of VLC.</p>

  <p>We are introducing an important number of fixes and improvements for all playback, notably for Blu-Ray, DVD, HLS, Ogg and MKV files; but also for Youtube, Vimeo, Koreus and Soundcloud.</p>

  <p>New support for the OPUS audio codec, including multichannel and streams.
…</p>
</blockquote>

<p>How the fuck is going from 2.0.3 to 2.0.4 the correct version bump for a <em>major</em> upgrade?</p>

<p>Jeez…</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[What is Text Normalization?]]></title>
    <link href="http://ianp.org/2012/04/17/what-is-text-normalization"/>
    <updated>2012-04-17T09:33:00+02:00</updated>
    <id>http://ianp.org/2012/04/17/what-is-text-normalization</id>
    <content type="html"><![CDATA[<p>In my <a href="/2012/04/16/how-many-words-make-a-string">previous post</a> I mentioned that some of the word counting approaches may be suitable if the input text had been normalized, but I didn’t really elaborate on what this means. According to <a href="https://en.wikipedia.org/wiki/Text_normalization">Wikipedia</a>:</p>

<blockquote>
  <p>Text normalization is a process by which text is transformed in some way to make it consistent in a way which it might not have been before.</p>
</blockquote>

<p>The article also gives some examples of the kind of transformations that are commonly performed. Of necessity, any normalization process is going to be application specific, but let’s assume for the sake of example that the word count is intended to be used in a writing application of some sort (a text editor or word processor). Given that we probably don’t care about <a href="http://www.unicode.org/reports/tr15/">Unicode normalization</a>, and definitely don’t care about anything which would change the words such as stemming or canonicalization. But maybe we could normalize all runs of whitespace into single spaces? Our original test string then changes from “Peter  piper  picked  a  peck  of  pickled  pepper . No — really — he did!” to “Peter piper picked a peck of pickled pepper . No — really — he did!”. The difference is probably hard to spot, but all of the doubled spaces in the first string have been replaces with single spaces, and the hair-spaces have been replaced with regular spaces.</p>

<p>How do the different word counting functions work now?</p>

<table class="tabular">
  <thead>
    <tr>
      <th>Method</th>
      <th style="text-align: right">Raw</th>
      <th style="text-align: right">Normalized</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Original Scanner</td>
      <td style="text-align: right">15</td>
      <td style="text-align: right">15</td>
    </tr>
    <tr>
      <td>Regular Expression</td>
      <td style="text-align: right">12</td>
      <td style="text-align: right">12</td>
    </tr>
    <tr>
      <td>String Components</td>
      <td style="text-align: right">18</td>
      <td style="text-align: right">15</td>
    </tr>
    <tr>
      <td>Char Components</td>
      <td style="text-align: right">22</td>
      <td style="text-align: right">15</td>
    </tr>
    <tr>
      <td>Linguistic tagger</td>
      <td style="text-align: right">12</td>
      <td style="text-align: right">12</td>
    </tr>
  </tbody>
</table>

<p>Better, but it still only leaves the same two functions returning the correct result (assuming of course that you <em>don’t</em> want to count strings of puncuation, this may or may not be the case in a code editor for example).</p>

<p>I can’t speak for the inner working of the linguistic tagger, but the reason that the regex based function works is that it is basing it’s approach on a <em>whitelist</em> rather than a <em>blacklist</em>. The regex basically says “these are valid word characters, everything else can be ignored” whereas all of the other functions take the stance “these are whitespace, eveything else must be part of a word”. Anybody who has done any web development or input validation generally will tell you that whitelists are almost always the correct approach to take. It’s just easier to enumerate all of the valid values for a given set than to try to list all of the exceptions.</p>

<h2 id="linguistic-tagger">Linguistic Tagger</h2>

<p>There are quite a few more options available for analysing text here, let’s start by counting sentences as well as words, this can be done by adding a count for sentences and keeping track of the current sentence based on it’s starting location. The interesting code is on lines 9 and 10:</p>

<p><code>objc
__block NSUInteger words = 0;
__block NSUInteger sentences = 0;
__block NSUInteger current_sentence = 0;
[tagger enumerateTagsInRange:NSMakeRange(0, [string length])
                      scheme:NSLinguisticTagSchemeTokenType
                     options:0
                  usingBlock:^(NSString* tag, NSRange token, NSRange sentence, BOOL *stop) {
  if ([tag isEqual:NSLinguisticTagWord]) ++words;
  if (!sentences || current_sentence != sentence.location) ++sentences;
  current_sentence = sentence.location;
}];
</code></p>

<p>Updating the <code>taggerWordCount</code> function with this code tells us that we still have 12 words, and that they are spread over 2 sentences, cool!</p>

<p>But what about that <code>schemes</code> parameter that we used to set up the tagger and run the enumeration? That allows the tagger to provide different types of information to the enumeration, we can tell the tagger to tag as much as it can by initializing the <code>schemes</code> variable with all available schemes. The <code>en-GB</code> string, by the way, is a <a href="http://tools.ietf.org/html/bcp47">BCP-47</a> code. The list of available schemes for this language is shown as a comment:</p>

<p>```objc
NSArray* schemes = [NSLinguisticTagger availableTagSchemesForLanguage:@”en-GB”];
NSLog(@”%@”, schemes);</p>

<p>// 2012-04-17 13:08:16.947 wordcounters[54440:707] (
//    TokenType,
//    Language,
//    Script
// )
```</p>

<p>According to Apple’s docs there are several different schemes available. One warning: if you use BCP-47 codes with more information in (such as <code>en-US</code> or <code>pt-BR</code>) then you will just get the basic 3 schemes shown above, using <code>en</code> gets the full list and other languages have varying levels of support.</p>

<p>Let’s alter the test string and see what the different <code>en</code> schemes give us. For a new test string I’m going to use <a href="http://www.mudcat.org/@displaysong.cfm?SongID=1242">this little ditty</a>:</p>

<p><code>objc
NSString* coffee = @"What I want - is a proper cup ’o coffee,"
                   @" Made in a proper copper coffee pot."
                   @" Ik kan van mijn punt,"
                   @" Ach ba mhaith liom cupán caife o ó pota caife cuí."
</code></p>

<p>The 3rd and 4th lines have been replaced with Dutch and Irish translations of the English words in order to test the language detection. Interesting to note here is the syntaxused for multi-line strings in Objective-C, and also that I’ve indented the following lines so that there is a space after the punctuation at the end of the preceeding line.</p>

<p>Let’s take a look at each scheme and what it gives us in this example.</p>

<ul>
  <li>
    <p><strong>Token Type</strong>
We can tell the words apart from the whitespace and punctuation by the tag. I could see this being useful for implementing smart punctuation in a word processor (like <a href="http://daringfireball.net/projects/smartypants/">SmartyPants</a>).</p>
  </li>
  <li>
    <p><strong>Lexical Class</strong>
Instead of just words this gives us nouns, adjectives, and so on; it also classifies some of the puntuation more precisely, for example <code>OpenQuote</code>. Possibly useful in a word processing application, or to provide input to a higher-level analyser.</p>
  </li>
  <li>
    <p><strong>Name Type</strong>
This attempts to detect people and place names in the text. In this example it identified “Made” as a place name, so it’s probably guessing at this based on the word capitalization.</p>
  </li>
  <li>
    <p><strong>Name Type or Lexical Class</strong>
As it suggests, a combination of the previous two schemes.</p>
  </li>
  <li>
    <p><strong>Lemma</strong>
This scheme performs word stemming, returning the stemmed word in the <code>tag</code> block parameter.</p>
  </li>
  <li>
    <p><strong>Language</strong>
This supposedly analysis each sentence to try to guess which language it is written in. I found that it worked fairly poorly when the language used the same script but did OK when they were different. In the example above it guesses that all of the text is in English, but if you change the 3rd line to “Аз не мога да ми.” (the same in Bulgarian) then it guesses this correctly.</p>
  </li>
  <li>
    <p><strong>Script</strong>
This is the script used in the token, for us it is always “Latn” for Latin, unless you make the substitution mentioned above in which case it correctly picks up “Cyrl” for the Bulgarian Cyrillic script.</p>
  </li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>For a simple word count it seems that the regular expression wins out, but the linguistic tagger provides some interesting additional information. One downside to the tagger is that it doesn’t seem to be extensible in any way, so you’re limited to those schemes and tags that Apple ship with the OS. There is no way to, for example, use this mechanism to tag keywords and operators in a code editor, which may be useful.</p>

<p>The code used for this post can be found in <a href="https://gist.github.com/2413356">this gist</a>.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How Many Words Make a String?]]></title>
    <link href="http://ianp.org/2012/04/16/how-many-words-make-a-string"/>
    <updated>2012-04-16T15:16:00+02:00</updated>
    <id>http://ianp.org/2012/04/16/how-many-words-make-a-string</id>
    <content type="html"><![CDATA[<p>A recent post on the <a href="http://iphonedevelopertips.com/data-file-management/count-the-number-of-words-in-an-string.html">iOS Developer Tips</a> blog provided a handy way to get the the word count for a string by using <code>NSScanner</code>, and asked for comments on alternative approaches. Pretty quickly there were a few different suggestions so I thought that I’d take a look at them to see how they compare. It turns out that the different approaches give pretty different results when run over the same test string! To be honest this isn’t much of a surprise, but what was surprising is just how different the results were.</p>

<p>I tested the original scanner based approach and also the first four alternatives from the comments. For the test string I used this:</p>

<p><code>objc
NSString* string = @"Peter  piper  picked  a  peck  of  pickled  pepper . No — really — he did!";
</code></p>

<p>there are a couple of things to note here: some of the spaces are doubled up, the period is spaced French-style (i.e. with a space before and after) and the em-dashes have hair-space at either side of them. It’s easier to see some of these features when you look at the same string in a proportional font: “Peter  piper  picked  a  peck  of  pickled  pepper . No — really — he did!”</p>

<p>Anyway, the various approaches gave very different word counts for that example:</p>

<table class="tabular">
  <thead>
    <tr>
      <th>Method</th>
      <th style="text-align: right">Count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Original Scanner</td>
      <td style="text-align: right">15</td>
    </tr>
    <tr>
      <td>Regular Expression</td>
      <td style="text-align: right">12</td>
    </tr>
    <tr>
      <td>String Components</td>
      <td style="text-align: right">18</td>
    </tr>
    <tr>
      <td>Char Components</td>
      <td style="text-align: right">22</td>
    </tr>
    <tr>
      <td>Linguistic tagger</td>
      <td style="text-align: right">12</td>
    </tr>
  </tbody>
</table>

<p>Anywhere from 12 to 22 words! Let’s take a look at the different approaches in turn.</p>

<h2 id="original-scanner">Original Scanner</h2>

<p>This is the original <code>NSScanner</code> based version from John’s post, here’s the code for it:</p>

<p><code>objc
NSUInteger scannerWordCount(NSString* string) 
{
  NSScanner* scanner = [NSScanner scannerWithString:string];
  NSCharacterSet* ws = [NSCharacterSet whitespaceAndNewlineCharacterSet];
  NSUInteger words = 0;
  while ([scanner scanUpToCharactersFromSet:ws intoString:nil])
    ++words;
  return words;
}
</code></p>

<p>This version correctly handles runs of whitespace, but it treats any non-space character as a valid word, so the French-spaced period get’s counted, as do the two em-dashes. Note however that this version <em>does</em> correctly pick up the four hair-spaces.</p>

<h2 id="regular-expression">Regular Expression</h2>

<p>This is my contribution:</p>

<p><code>objc
NSUInteger regexWordCount(NSString* string)
{
  NSRegularExpression* regex = [NSRegularExpression regularExpressionWithPattern:@"\\w+" options:0 error:nil];
  return [regex numberOfMatchesInString:string options:0 range:NSMakeRange(0, [string length])];
}
</code></p>

<p>Obviously this isn’t production code as there is no error handling (or caching of the compiled regex, which may or may not make sense here). But I’d say that this version gives the correct result, both ignoring the French-stop and em-dashes, and handling all of the spaces correctly.</p>

<h2 id="string-components">String Components</h2>

<p>This is by far the simplest solution, provided by Frank in the comments:</p>

<p><code>objc
NSUInteger componentsByStringWordCount(NSString* string)
{
  return [[string componentsSeparatedByString:@" "] count];
}
</code></p>

<p>Unfortunately it doesn’t work at all for this string. Just looking at an actual space character means that the double spaces get counted twice, and the entire substring “No — really — he” gets treated as a single word!</p>

<p>Note though, that this approach is <em>really</em> easy to understand, and would be good if the input text had already been heavily normalized.</p>

<h2 id="char-components">Char Components</h2>

<p>Almost the same as the previous version, except that this uses an <code>NSCharacterSet</code> instead of a string:</p>

<p><code>objc
NSUInteger componentsByCharsWordCount(NSString* string)
{
  NSCharacterSet* ws = [NSCharacterSet whitespaceAndNewlineCharacterSet];
  return [[string componentsSeparatedByCharactersInSet:ws] count];
}
</code></p>

<p>Compared to the previous version this one still double counts the 2-space wide spaces, but it correctly detects the hair-spaces surrounding the em-dashes. Useful I guess if your text has been partially normalized by collapsing runs of spaces.</p>

<h2 id="linguistic-tagger">Linguistic Tagger</h2>

<p>This one was interesting as it’s an API that I haven’t seen before:</p>

<p><code>objc
NSUInteger taggerWordCount(NSString* string)
{
  NSArray* schemes = [NSArray arrayWithObject:NSLinguisticTagSchemeTokenType];
  NSLinguisticTagger* tagger = [[NSLinguisticTagger alloc] initWithTagSchemes:schemes
                                                                      options:0];
  [tagger setString:string];
  __block NSUInteger words = 0;
  [tagger enumerateTagsInRange:NSMakeRange(0, [string length])
                        scheme:NSLinguisticTagSchemeTokenType
                       options:0
                    usingBlock:^(NSString* tag, NSRange token, NSRange sentence, BOOL *stop) {
    if ([tag isEqualTo: NSLinguisticTagWord]) ++words;
  }];
  return words;
}
</code></p>

<p>This code returns the correct number of words, so we have another winner here! Although the code is definitely more complicated than the regex based version above. Also, the originally posted code gave a result of 30, as it also calls the block for whitespace and punctuation, you need to use the <code>tag</code> block parameter to disambiguate these.</p>

<p>The linguistic tagger provides a number of advanced features which may be useful if you need more than just a simple word count though. Note, for example, the <code>sentence</code> block parameter which could be used to give a sentence count as well as a word count.</p>

<h2 id="conclusion">Conclusion</h2>

<p>For most text the simplest solution is to use a regular expression here. If your input text has already been normalized then the <code>componentsSeparatedByString:</code> based approach is probably the easiest to use. The linguistic tagger allows for more advanced analysis of the text.</p>

<p><strong>Update:</strong> all of the code here, plus a <code>main</code> function to call it, is available as a <a href="https://gist.github.com/2401251">gist</a>.</p>

<p><strong>Update:</strong> I talk a little more about normalization and linguistic tagging in <a href="/2012/04/17/what-is-text-normalization">this post</a>.</p>

]]></content>
  </entry>
  
</feed>
